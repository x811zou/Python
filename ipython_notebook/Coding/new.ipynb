{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scarlett/github/Coding_pythons/newenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "#source /home/scarlett/github/ipython_notebook/Coding_pythons/myenv/bin/activate\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install new packages:\n",
    "- source /home/scarlett/github/Coding_pythons/newenv/bin/activate\n",
    "- pip install <package_name>\n",
    "- pip list\n",
    "- import <package_name>\n",
    "- deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "- deep learning is everywhere:\n",
    "    - language translation\n",
    "    - self-driving cars\n",
    "    - medical diagnostics\n",
    "    - chatbots\n",
    "\n",
    "- used on multiple data types: images, text and audio\n",
    "- traditional machine learning: relies on hand-crafted feature engineering\n",
    "- deep learning: enables feature learning from raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is deep learning?\n",
    "- An architecture of network consists of input, hidden layers and output\n",
    "- A network can have one or many hidden layers\n",
    "- Require 100K data\n",
    "- pytorch supports tabular data, also unstructral data like image (torchvision), audio data (torchaudio), text data (torchtext)\n",
    "- deep learning often requires a GPU, which, compard to a CPU can offer: parallel computing capabilities, faster training times and better performance\n",
    "- tensors are multidimensional representations of their elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make tensor: load from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "tensor = torch.tensor(lst)\n",
    "tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load from NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "np_array = np.array(array)\n",
    "np_tensor = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor operations - most numpy array operations can be performedon PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12],\n",
       "        [14, 16, 18]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [16, 25, 36],\n",
       "        [49, 64, 81]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * np_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural net\n",
    "### basic two layer NN without hidden layer\n",
    "- first layer: input, second layer: linear layer\n",
    "- each linear layer has a .weight and .bias associated\n",
    "- nn.linear performs\n",
    "    - when input_tensor is passed to linear_layer, the linear operation performed is matrix multiplication of input_tensor and the weights, followed by adding in the bias\n",
    "    - input X, weights W0, bias b0 --> y0 = W0 * X +b0; in pytorch: output = W0 * input + b0\n",
    "    - initially, when we call nn.Linear(), weights and biases are initialized randomly, so they are not yet useful\n",
    "    - we have to tune these weights and biases\n",
    "- two-layer network summary:\n",
    "    - took 1 by 3 input as the first layer (1 linear layer with specific arguments as the second layer, and retured a 1 by 2 output)\n",
    "    - linear layers have connections (or arrows) between each input and output neuron, making them fully connected\n",
    "        - networks with only linear layers are called: \"fully connected networks\"\n",
    "        - each neuron in one layer is connected to each neuron in the next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0560, -0.6962]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## create input_tensor with 3 features\n",
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]], dtype=torch.float32)\n",
    "\n",
    "## define first linear layer ( a linear layer takes an input, applies a linear fxn, and returns output)\n",
    "linear_layer = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "## pass input through linear layer\n",
    "output = linear_layer(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2942, -0.0729, -0.2760],\n",
       "        [-0.3467, -0.1545, -0.2645]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1262, -0.5679], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer model: Stacking layers with nn.Sequential()\n",
    "- this model takes input, passes it to each linear layer in sequence, and returns output\n",
    "    - the first layer takes input with 10 features, and output with a tensor with 18 features\n",
    "    - the second layer takes input with 18 features, and output with a tensor with 20 features\n",
    "    - the third layer takess input with 20 featuresl and output with a tensor with 5 features\n",
    "- output is not linear until each layer has tuned weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,18), \n",
    "    nn.Linear(18,20), \n",
    "    nn.Linear(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8991, 0.5175, 0.2633, 0.3706, 0.5805, 0.0322, 0.7388, 0.3716, 0.0867,\n",
       "         0.3902]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a input_tensor with ten features (neurons)\n",
    "input_tensor = torch.rand(1,10)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass input_tensor through model\n",
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise, you will implement a small neural network containing two linear layers. The first layer takes an eight-dimensional input, and the last layer outputs a one-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4597]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Implement a small neural network with exactly two linear layers\n",
    "model = nn.Sequential(nn.Linear(8,5),\n",
    "                      nn.Linear(5,1)\n",
    "                     )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
