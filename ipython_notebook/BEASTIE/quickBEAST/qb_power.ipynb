{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from pickle import dump, load\n",
    "from math import log,log2\n",
    "sys.path.append('/home/scarlett/github/Ipy_notebook')\n",
    "from Python.quickBeast import Generate_path_qb,Calculate_power_type1error_pval, get_filename, get_qb_p_values, get_NS_p_values\n",
    "from Python.power import Prepare_data_fix\n",
    "BEASTIE_path=\"/home/scarlett/github/BEASTIE\"\n",
    "sys.path.append(str(BEASTIE_path))\n",
    "from BEASTIE import predict_lambda_GAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Power curve across different models<br>1. testing case<br>2. parametrized simulator<br>3. semi empirical simulator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC_path=\"/data2/stan\"\n",
    "gam_model= load(open(\"/home/scarlett/github/BEASTIE/BEASTIE/iBEASTIE3_s0.7_GAM/gam4_lambdamodel.pkl\", \"rb\"))\n",
    "expected_type1error=0.05/1000\n",
    "candidate_lambdas = np.linspace(1, 3, 2000)\n",
    "null_cutoff=95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_to_directory = {\n",
    "    'quickBEAST': '/data2/stan/quickBEAST/a8.789625_b8.789625/lambda0.04545/parametrized/ASE_0.05_error',\n",
    "    'BEASTIE': '/data2/stan/BEASTIE3-pi0.05/sigma0.7/parametrized/ASE_0.05_error/output_pkl',\n",
    "    'NS': '/data2/stan/binomial/parametrized/ASE_0.05_error/NS_p',\n",
    "    'MS': '/data2/stan/binomial/parametrized/ASE_0.05_error/MS_p',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (ngenes, hets, depth, theta, method)\n",
    "inputs = []\n",
    "\n",
    "# BEASTIE inputs\n",
    "files = os.listdir(method_to_directory['BEASTIE'])\n",
    "# split files like \"g-1000_h-5_d-90_t-0.75_s-0.7.pickle\" or \"g-1000_h-5_d-90_t-1_s-0.7.pickle\" into parts using regex\n",
    "for file in files:\n",
    "    match = re.match(r\"g-(1000)_h-(\\d+)_d-(\\d+)_t-(\\d.*)_s-(\\d+\\.\\d+).pickle\", file)\n",
    "    if match:\n",
    "        ngenes = int(match.group(1))\n",
    "        hets = int(match.group(2))\n",
    "        depth = int(match.group(3))\n",
    "        theta = float(match.group(4))\n",
    "        sigma = float(match.group(5))\n",
    "        inputs.append((ngenes, hets, depth, theta, f\"BEASTIE-s{sigma}\"))\n",
    "\n",
    "\n",
    "# quickBEAST inputs\n",
    "files = os.listdir(method_to_directory['quickBEAST'])\n",
    "# split files like \"g-1000_h-8_d-60_t-1.txt\" into parts using regex\n",
    "for file in files:\n",
    "    match = re.match(r\"g-(1000)_h-(\\d+)_d-(\\d+)_t-(\\d+).txt\", file)\n",
    "    if match:\n",
    "        ngenes = int(match.group(1))\n",
    "        hets = int(match.group(2))\n",
    "        depth = int(match.group(3))\n",
    "        theta = float(match.group(4))\n",
    "        inputs.append((ngenes, hets, depth, theta, \"quickBEAST\"))\n",
    "\n",
    "# NS inputs\n",
    "files = os.listdir(method_to_directory['NS'])\n",
    "# split files like \"g-1000_h-6_d-90_t-0.25.pickle\" into parts using regex\n",
    "for file in files:\n",
    "    match = re.match(r\"g-(1000)_h-(\\d+)_d-(\\d+)_t-(\\d.*).pickle\", file)\n",
    "    if match:\n",
    "        ngenes = int(match.group(1))\n",
    "        hets = int(match.group(2))\n",
    "        depth = int(match.group(3))\n",
    "        theta = float(match.group(4))\n",
    "        inputs.append((ngenes, hets, depth, theta, f\"NS\"))\n",
    "\n",
    "# inputs =[]\n",
    "\n",
    "# MS inputs\n",
    "files = os.listdir(method_to_directory['MS'])\n",
    "# split files like \"g-1000_h-6_d-90_t-0.25.pickle\" into parts using regex\n",
    "for file in files:\n",
    "    match = re.match(r\"g-(1000)_h-(\\d+)_d-(\\d+)_t-(\\d+).pickle\", file)\n",
    "    if match:\n",
    "        ngenes = int(match.group(1))\n",
    "        hets = int(match.group(2))\n",
    "        depth = int(match.group(3))\n",
    "        theta = float(match.group(4))\n",
    "        inputs.append((ngenes, hets, depth, theta, f\"MS\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nhets, depth, ngenes, sigma, method, power, t1error\n",
    "\n",
    "\n",
    "method_to_directory: {\n",
    "    'quickBEAST': 'data2/stan/quickBEAST/a8.789625_b8.789625/lambda0.04545/parametrized/ASE_0.05_error',\n",
    "    'BEASTIE': '/data2/stan/BEASTIE3-pi0.05/sigma0.7/parametrized/ASE_0.05_error/output_pkl',\n",
    "    'NS': '/data2/stan/binomial/parametrized/ASE_0.05_error/NS_p',\n",
    "    'MS': '/data2/stan/binomial/parametrized/ASE_0.05_error/MS_p',\n",
    "}\n",
    "\n",
    "# do beastie files\n",
    "# list files in BEASTIE directory\n",
    "\n",
    "inputs = []\n",
    "files = os.listdir(path_model)\n",
    "# split files like \"g-1000_h-4_d-90_t-0.25.pickle\" into parts using regex\n",
    "for file in files:\n",
    "    match = re.match(r'g-(\\d+)_h-(\\d+)_d-(\\d+)_t-(\\d+\\.\\d+).pickle', file)\n",
    "    if match:\n",
    "        ngenes = match.group(1)\n",
    "        nhets = match.group(2)\n",
    "        depth = match.group(3)\n",
    "        sigma = match.group(4)\n",
    "        method = 'BEASTIE'\n",
    "        inputs.append((nhets, depth, ngenes, sigma, method))\n",
    "\n",
    "\n",
    "# process files\n",
    "\n",
    "def compute_power_t1error(nhets, depth, ngenes, sigma, method):\n",
    "    # read file\n",
    "\n",
    "    if method == 'beastie':\n",
    "        ...\n",
    "    elif method == 'ns':\n",
    "        ...\n",
    "\n",
    "    return power, t1error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['nhets', 'depth', 'ngenes', 'sigma', 'method', 'power', 't1error'])\n",
    "for (nhets, depth, ngenes, sigma, method) in inputs:\n",
    "    power, t1error = compute_power(nhets, depth, ngenes, sigma, method)\n",
    "    df = df.append({'nhets': nhets, 'depth': depth, 'ngenes': ngenes, 'sigma': sigma, 'method': method, 'power': power, 't1error': t1error}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene,hets=None,depth=None,sigma=None,num=3,if_AA=False,calculation=\"max_prob\"):\n",
    "    print(f\">>>> {list} calculated using FDR corrected pvalues\")\n",
    "    expected_type1error = float(alpha/int(gene))\n",
    "    source=\"/data2/stan/\"\n",
    "    gam_model= load(open(\"/home/scarlett/github/BEASTIE/BEASTIE/iBEASTIE3_s0.7_GAM/gam4_lambdamodel.pkl\", \"rb\"))\n",
    "    candidate_lambdas = np.linspace(1, 3, 2000)\n",
    "    # judge whether  2 of the 4 are None, and 2 of the 4 are not None\n",
    "    theta_pos=theta_alt\n",
    "    theta_neg=1\n",
    "\n",
    "    var=[gene,hets,depth,sigma]        \n",
    "    if var.count(None)!=2:\n",
    "        raise Exception('Two variables have to be set to None. The number of None from input was {}'.format(var.count(None)))\n",
    "    \n",
    "    path_model, path_qb, path_NS, path_MS = Generate_path_qb(source,model,sigma,workdir)\n",
    "    d_group,var,var_map_np,fixed_var_np,var_fullname_map_np,variable_var_np,pos_pd,neg_pd = Prepare_data_fix(gene, hets, depth, sigma,source,model,workdir,theta_pos,theta_neg=1,Num_para=2)\n",
    "\n",
    "    ############################################################\n",
    "    n_hets = pos_pd[var_map_np[np.array(var) == None][0]].unique()\n",
    "    #read_depth = pos_pd[var_map_np[np.array(var) == None][1]].unique()\n",
    "\n",
    "    if num == None:\n",
    "        num = 3\n",
    "    else:\n",
    "        num = int(num)\n",
    "\n",
    "    row = math.ceil(float(len(d_group))/num)\n",
    "    fig, axs = plt.subplots(row, num, figsize = (17,6*row))\n",
    "    if (row * num > len(d_group)):\n",
    "        for i in range(row * num - len(d_group)):\n",
    "            axs.flat[-1-i].set_axis_off()\n",
    "\n",
    "    xlabels = \"Data with %s percent error, gene: %s , sigma: %s,alpha at %s\"%(str(workdir),gene,sigma,alpha)\n",
    "\n",
    "    labels = \"\"\n",
    "\n",
    "    for i, each in enumerate(n_hets):\n",
    "        #print(f\"hets- {each}\")\n",
    "        current_group_pos_list = pos_pd[pos_pd[var_map_np[np.array(var) == None][0]] == each].index\n",
    "        current_group_neg_list = neg_pd[neg_pd[var_map_np[np.array(var) == None][0]] == each].index\n",
    "        # \n",
    "        power_qb_list=[]\n",
    "        power_NS_list=[]\n",
    "        power_MS_list=[]\n",
    "        # \n",
    "        type1_qb_list=[]\n",
    "        type1_NS_list=[]\n",
    "        type1_MS_list=[]    \n",
    "        read_depth = [] \n",
    "\n",
    "        tdr_qb_list = []\n",
    "        tdr_NS_list = []\n",
    "        tdr_MS_list = []\n",
    "\n",
    "        fdr_qb_list = []\n",
    "        fdr_NS_list = []\n",
    "        fdr_MS_list = []\n",
    "\n",
    "        for idx in range(len(current_group_pos_list)):\n",
    "            reduced_file_pos = current_group_pos_list[idx].rsplit(\"_\",1)[0]+\".pickle\"\n",
    "            reduced_file_neg = current_group_neg_list[idx].rsplit(\"_\",1)[0]+\".pickle\"\n",
    "            g=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[0].rsplit(\"-\")[1]\n",
    "            h=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[1].rsplit(\"-\")[1]\n",
    "            d=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[2].rsplit(\"-\")[1]\n",
    "            s=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[4].rsplit(\"-\")[1]\n",
    "            hets=int(h)\n",
    "            totalcount=int(h)*int(d)\n",
    "            #\n",
    "            #predicted_lambda = predict_lambda_GAM.get_lambda_from_gam(gam_model, log(hets), log(totalcount), expected_type1error, candidate_lambdas = np.linspace(1, 3, 2000))\n",
    "            # \n",
    "            ns_NEG,ns_POS,qb_NEG,qb_POS = get_filename(current_group_pos_list[idx],current_group_neg_list[idx])\n",
    "            qb_POS_p, qb_NEG_p,_,_ = get_qb_p_values(qb_POS, qb_NEG, path_qb)\n",
    "            ns_POS_p, ns_NEG_p = get_NS_p_values(ns_POS, ns_NEG, path_NS)\n",
    "            ms_POS_p, ms_NEG_p = get_NS_p_values(ns_POS, ns_NEG, path_MS)\n",
    "            qb_power, qb_type1error, qb_tdr, qb_fdr,qb_fdr_power,qb_fdr_type1 = Calculate_power_type1error_pval(qb_POS_p,qb_NEG_p,threshold=alpha)\n",
    "            ns_power, ns_type1error, ns_tdr, ns_fdr,ns_fdr_power,ns_fdr_type1 = Calculate_power_type1error_pval(ns_POS_p,ns_NEG_p,threshold=alpha)\n",
    "            ms_power, ms_type1error, ms_tdr, ms_fdr,ms_fdr_power,ms_fdr_type1 = Calculate_power_type1error_pval(ms_POS_p,ms_NEG_p,threshold=alpha)\n",
    "            # \n",
    "\n",
    "            power_qb_list.append(qb_fdr_power) \n",
    "            power_NS_list.append(ns_fdr_power)\n",
    "            power_MS_list.append(ms_fdr_power)\n",
    "\n",
    "            type1_qb_list.append(qb_fdr_type1) \n",
    "            type1_NS_list.append(ns_fdr_type1)\n",
    "            type1_MS_list.append(ms_fdr_type1)\n",
    "\n",
    "            tdr_qb_list.append(qb_tdr) \n",
    "            tdr_NS_list.append(ns_tdr)\n",
    "            tdr_MS_list.append(ms_tdr)\n",
    "\n",
    "            fdr_qb_list.append(qb_fdr) \n",
    "            fdr_NS_list.append(ns_fdr)\n",
    "            fdr_MS_list.append(ms_fdr)\n",
    "\n",
    "            read_depth.append(d)\n",
    "        if list == \"power\":\n",
    "            #list_beastie = [float(item) for item in power_model_list]\n",
    "            list_qb = [float(item) for item in power_qb_list]\n",
    "            list_NS = [float(item) for item in power_NS_list]\n",
    "            list_MS =  [float(item) for item in power_MS_list]\n",
    "            title = \"power (FDR)\"\n",
    "        elif list == \"type1\":\n",
    "            #list_beastie = [float(item) for item in type1_model_list]\n",
    "            list_qb = [float(item) for item in type1_qb_list]\n",
    "            list_NS = [float(item) for item in type1_NS_list]\n",
    "            list_MS = [float(item) for item in type1_MS_list]\n",
    "            title = \"type1error (FDR)\"\n",
    "        elif list == \"tdr\":\n",
    "            list_qb = [float(item) for item in tdr_qb_list]\n",
    "            list_NS = [float(item) for item in tdr_NS_list]\n",
    "            list_MS = [float(item) for item in tdr_MS_list]\n",
    "            title = \"tdr (FDR)\"\n",
    "        elif list == \"fdr\":\n",
    "            list_qb = [float(item) for item in fdr_qb_list]\n",
    "            list_NS = [float(item) for item in fdr_NS_list]\n",
    "            list_MS = [float(item) for item in fdr_MS_list]\n",
    "            title = \"fdr (FDR)\"\n",
    "        read_depth = [int(item) for item in read_depth]\n",
    "        # for each read depth, we plot    \n",
    "        g=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[0].rsplit(\"-\")[1]\n",
    "        h=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[1].rsplit(\"-\")[1]\n",
    "        d=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[2].rsplit(\"-\")[1]\n",
    "        s=current_group_pos_list[idx].rsplit(\".pickle\")[0].rsplit(\"_\")[4].rsplit(\"-\")[1]\n",
    "        var_dict = {\"gene\":g, \"hets\": h, \"depth\": d, \"sigma\": s}\n",
    "        for each in variable_var_np:\n",
    "            if each != var_fullname_map_np[np.array(var) == None][0]:\n",
    "                labels += each+\":\"+var_dict[each]+' '\n",
    "\n",
    "        #axs.flat[i].plot(read_depth, list_beastie,'--o',color = \"dodgerblue\",label=f\"{model} gam λ\")\n",
    "        axs.flat[i].plot(read_depth, list_NS,'--o',color=\"darkorange\",label=\"Naive Sum\")\n",
    "        axs.flat[i].plot(read_depth, list_MS,'--o',color= \"limegreen\",label=\"Major Site\")\n",
    "        axs.flat[i].plot(read_depth, list_qb,'--o',color = \"crimson\",label=\"qb fixed λ (t)\")\n",
    "        # set y-axis label\n",
    "        if list == \"power\" or list == \"tdr\":\n",
    "            axs.flat[i].set_ylabel(title,fontsize=12)\n",
    "            axs.flat[i].set_ylim(0,1.1)\n",
    "        elif list == \"type1\" or list == \"fdr\":\n",
    "            axs.flat[i].set_ylabel(title,fontsize=12)\n",
    "            axs.flat[i].set_ylim(0,1.1)\n",
    "        # set x-axis label\n",
    "        axs.flat[i].set_xlabel(\"Read Depth per het site\",fontsize=12)\n",
    "        axs.flat[i].legend(loc='best',fontsize=13)\n",
    "        axs.flat[i].set_title(var_fullname_map_np[np.array(var) == None][0]+\":\" + var_dict[var_fullname_map_np[np.array(var) == None][0]],fontsize=20)\n",
    "\n",
    "    plt.suptitle(xlabels,fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parametrized simulator\n",
    "### 0% phasing error rate, with 1,000 genes under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"power\"\n",
    "alpha=0.05\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"power\"\n",
    "alpha=0.05\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"type1\"\n",
    "cutoff=95\n",
    "alpha=0.05\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"tdr\"\n",
    "cutoff=95\n",
    "alpha=0.05\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"fdr\"\n",
    "cutoff=95\n",
    "alpha=0.1\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"fdr\"\n",
    "cutoff=95\n",
    "alpha=0.05\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"fdr\"\n",
    "cutoff=95\n",
    "alpha=0.01\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "# list: power, FDR , type1error\n",
    "list=\"power\"\n",
    "cutoff=95\n",
    "alpha=0.05\n",
    "\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,cutoff,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data2/stan\"\n",
    "model=\"BEASTIE3-pi0.05\"\n",
    "workdir=\"parametrized/ASE_0.05_error\"\n",
    "theta_alt=0.5\n",
    "gene=1000\n",
    "sigma=0.7\n",
    "list=\"type1\"\n",
    "cutoff=95\n",
    "alpha=0.05\n",
    "Find_cutoff_from_Null_allmodels(list,model,workdir, theta_alt,cutoff,alpha,gene=gene,hets=None,depth=None,sigma=sigma,num=3,if_AA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
