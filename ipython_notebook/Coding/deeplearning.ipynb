{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/python3\n"
     ]
    }
   ],
   "source": [
    "#source /home/scarlett/github/ipython_notebook/Coding_pythons/myenv/bin/activate\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install new packages:\n",
    "- source /home/scarlett/github/Coding_pythons/newenv/bin/activate\n",
    "- pip install <package_name>\n",
    "- pip list\n",
    "- import <package_name>\n",
    "- deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "- deep learning is everywhere:\n",
    "    - language translation\n",
    "    - self-driving cars\n",
    "    - medical diagnostics\n",
    "    - chatbots\n",
    "\n",
    "- used on multiple data types: images, text and audio\n",
    "- traditional machine learning: relies on hand-crafted feature engineering\n",
    "- deep learning: enables feature learning from raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is deep learning?\n",
    "- An architecture of network consists of input, hidden layers and output\n",
    "- A network can have one or many hidden layers\n",
    "- Require 100K data\n",
    "- pytorch supports tabular data, also unstructral data like image (torchvision), audio data (torchaudio), text data (torchtext)\n",
    "- deep learning often requires a GPU, which, compard to a CPU can offer: parallel computing capabilities, faster training times and better performance\n",
    "- tensors are multidimensional representations of their elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural net\n",
    "### basic two layer NN without hidden layer\n",
    "- first layer: input, second layer: linear layer\n",
    "- each linear layer has a .weight and .bias associated\n",
    "- nn.linear performs\n",
    "    - when input_tensor is passed to linear_layer, the linear operation performed is matrix multiplication of input_tensor and the weights, followed by adding in the bias\n",
    "    - input X, weights W0, bias b0 --> y0 = W0 * X +b0; in pytorch: output = W0 * input + b0\n",
    "    - initially, when we call nn.Linear(), weights and biases are initialized randomly, so they are not yet useful\n",
    "    - we have to tune these weights and biases\n",
    "- two-layer network summary:\n",
    "    - took 1 by 3 input as the first layer (1 linear layer with specific arguments as the second layer, and retured a 1 by 2 output)\n",
    "    - linear layers have connections (or arrows) between each input and output neuron, making them fully connected\n",
    "        - networks with only linear layers are called: \"fully connected networks\"\n",
    "        - each neuron in one layer is connected to each neuron in the next layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer model: Stacking layers with nn.Sequential()\n",
    "- this model takes input, passes it to each linear layer in sequence, and returns output\n",
    "    - the first layer takes input with 10 features, and output with a tensor with 18 features\n",
    "    - the second layer takes input with 18 features, and output with a tensor with 20 features\n",
    "    - the third layer takess input with 20 featuresl and output with a tensor with 5 features\n",
    "- output is not linear until each layer has tuned weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise, you will implement a small neural network containing two linear layers. The first layer takes an eight-dimensional input, and the last layer outputs a one-dimensional tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Training First NN with PyTorch\n",
    "### Section 2.1 Running a forward pass\n",
    "- input data is **passed forward** or **propagated** through a network\n",
    "- computations performed at each layer\n",
    "- outputs of each layer passed to each subsequent layer\n",
    "- output of final layer: \"prediction\"\n",
    "- used for both **training** and prediction\n",
    "- some possible outputs:\n",
    "    - binary classification\n",
    "    - multiclass classification\n",
    "    - regression values\n",
    "- results would not be meaningful untill we use backpropagation to update weights and biases\n",
    "- there is also a backward pass\n",
    "    - used to update weights and baises during training\n",
    "    - in the training loop: \n",
    "        1. propagate data forward\n",
    "        2. compare outputs to the true values (ground-truth)\n",
    "        3. backpropagate to update model weights and baises\n",
    "        4. repeaat weights and biases are tuned to produce useful outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary classificationl forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1194, -1.0176, -1.6571, -0.5804, -0.8895,  0.8564],\n",
       "        [-0.3560, -0.9500,  0.7982, -2.0451,  0.0645, -0.2077],\n",
       "        [ 0.2534,  0.3284,  0.9133,  0.4515, -1.0231,  0.3404],\n",
       "        [-0.1512, -0.7672, -0.4814,  1.2046, -2.0647,  1.5411],\n",
       "        [-0.6916,  0.9859,  0.0247,  0.7615,  0.1130,  0.5115]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create input data of shape 5*6\n",
    "data = torch.randn(5, 6)\n",
    "input_data = data\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5731],\n",
      "        [0.4194],\n",
      "        [0.5996],\n",
      "        [0.5715],\n",
      "        [0.5886]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# create binary classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 3),\n",
    "    nn.Linear(3, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# pass input data through model\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2 Building a binary classifier in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3 From regression to multi-class classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4 Using loss function to assess model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5 Creating one-hot encoded labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.6 Calculating cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.7 Using derivatives to update model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.8 Estimating a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.9 Accessing the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.9 Updating the weights manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.10 Using the PyTorch optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.11 Writing our first training loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
